# Classification
### Classification using Support Vector Machines, K Nearest Neighbors, Feedforward Neural Networks

The Classificationg_Methods,Results.pdf explores three well-known supervised learning classifiers and their ability to correctly classify new samples from different data sets. 
The classifiers used were K-Nearest Neighbors (KNN), Support Vector Machines (SVM) (using LIBSVM), and Artificial Neural Networks (ANN), the matlab files for each classifier and for splitting and shuffling the data are included.

Data:
######Diabetic Retinopathy Data Set, http://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set# 
Balint Antal, Andras Hajdu: An ensemble-based system for automatic screening of diabetic retinopathy, Knowledge-Based Systems 60 (April 			2014), 20-27. 
The  data set is based on features extracted from the Messidor image data set.

######Isolet Data Set, https://archive.ics.uci.edu/ml/datasets/ISOLET
Fanty, M., Cole, R. (1991). Spoken letter recognition. In Lippman, R. P., Moody, J., and Touretzky, D. S. (Eds). Advances in Neural Information Processing Systems 3. San Mateo, CA: Morgan Kaufmann. 

Dietterich, T. G., Bakiri, G. (1991) Error-correcting output codes: A general method for improving multiclass inductive learning programs. Proceedings of the Ninth National Conference on Artificial Intelligence (AAAI-91), Anaheim, CA: AAAI Press. 

Dietterich, T. G., Bakiri, G. (1994) Solving Multiclass Learning Problems via Error-Correcting Output Codes.

######EEG Data Set, http://www.bbci.de/competition/iii/ 
Data Set V, Mill√°n, J. del R.. On the need for on-line learning in brain-computer interfaces Proc. Int. Joint Conf. on Neural Networks., 2004.
